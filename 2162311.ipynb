{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、背景\n",
    "\n",
    "半监督学习（Semi-Supervised Learning）是指通过大量无标注数据和少量有标注数据完成模型训练，解决具有挑战性的模式识别任务。近几年，随着计算硬件性能的提升和大量大规模标注数据集的开源，基于深度卷积神经网络(Deep Convolutional Neural Networks, DCNNs)的监督学习研究取得了革命性进步。然而，监督学习模型的优异性能要以大量标注数据作为支撑，可现实中获得数量可观的标注数据十分耗费人力物力（例如：获取像素级标注数据）。于是，半监督学习逐渐成为深度学习领域的热门研究方向，只需要少量标注数据就可以完成模型训练过程，更适用于现实场景中的各种任务。\n",
    "\n",
    "[第三届中国AI+创新创业大赛：半监督学习目标定位竞赛](https://aistudio.baidu.com/aistudio/competition/detail/78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、数据集介绍\n",
    "\n",
    "训练数据集包括50,000幅像素级有标注的图像，共包含500个类，每个类100幅图像；\n",
    "A榜测试数据集包括11,878幅无标注的图像；\n",
    "B榜测试数据集包括10,989幅无标注的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据集至data/目录\r\n",
    "!unzip -qo data/data95249/train_50k_mask.zip -d data/\r\n",
    "!unzip -oq data/data95249/第一阶段test.zip -d data/\r\n",
    "!unzip -oq data/data95249/train_image.zip -d data/\r\n",
    "!unzip -oq data/data100087/B榜测试数据集.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据集检查和分析，检查完成后，生成work/data_analyse_and_check.log和work/img_pixel_statistics.pkl\r\n",
    "#%cd work/\r\n",
    "#!python check.py --data_dir data/ --num_classes 2 \r\n",
    "#%cd /home/aistudio/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.训练集统计信息\n",
    "\n",
    "Image channels statistics\n",
    "Image channels = [3]\n",
    "\n",
    "Image size statistics:\n",
    "max width = 4288  min width = 24  max height = 3456  min height = 30\n",
    "\n",
    "Label class statistics:\n",
    "(label class, percentage, total pixel number) = [(0, 0.7167, 5107091274), (255, 0.2833, 2018825997)] \n",
    "\n",
    "## 2.验证集统计信息\n",
    "\n",
    "Image channels statistics\n",
    "Image channels = [3]\n",
    "\n",
    "Image size statistics:\n",
    "max width = 3648  min width = 31  max height = 3264  min height = 48\n",
    "\n",
    "Label class statistics:\n",
    "(label class, percentage, total pixel number) = [(0, 0.7186, 1320353167), (255, 0.2814, 517136074)] \n",
    "\n",
    "## 3.测试集统计信息\n",
    "\n",
    "Image channels statistics\n",
    "Image channels = [3]\n",
    "\n",
    "Image size statistics:\n",
    "max width = 4288  min width = 67  max height = 3584  min height = 75\n",
    "value range: \n",
    "img_min_value = [0, 0, 0] \n",
    "img_max_value = [255, 255, 255]\n",
    "\n",
    "\n",
    "## 4.图像集Mean和Std\n",
    "\n",
    "Count the channel-by-channel mean and std of the image:\n",
    "mean = [102.70997161 115.73388749 120.92191048]\n",
    "std = [57.97585899 57.8573095  58.89195734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#每个通道像素统计信息\r\n",
    "%matplotlib inline\r\n",
    "import pickle\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "path = 'work/img_pixel_statistics.pkl'\r\n",
    "with open(path, 'rb') as f:\r\n",
    "    percentage, img_value_num = pickle.load(f)\r\n",
    "\r\n",
    "for k in range(len(img_value_num)):\r\n",
    "    print('channel = {}'.format(k))\r\n",
    "    plt.bar(\r\n",
    "        list(range(len(img_value_num[k]))),\r\n",
    "        img_value_num[k],\r\n",
    "        width=1,\r\n",
    "        log=True)\r\n",
    "    plt.xlabel('image value')\r\n",
    "    plt.ylabel('number')\r\n",
    "    plt.title('channel={}'.format(k))\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、解题思路\n",
    "\n",
    "## 1.半监督分割的思路为两种：self-training和consistency learning。一般来说，self-training是离线处理的过程，而consistency learning是在线处理的。\n",
    "\n",
    "\n",
    "\n",
    "（1）Self-training\n",
    "\n",
    "Self-training主要分为3步。\n",
    "\n",
    "第一步，我们在有标签数据上训练一个模型。\n",
    "\n",
    "第二步，我们用预训练好的模型，为无标签数据集生成伪标签。\n",
    "\n",
    "第三步，使用有标注数据集的真值标签，和无标注数据集的伪标签，重新训练一个模型。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ed18d338ea4a4f5d9c25875c197b841cc7d8c1b6c6ed4683992420df43912f14)\n",
    "\n",
    "\n",
    "（2）Consistency learning\n",
    "\n",
    "Consistency learning的核心idea是：鼓励模型对经过不同变换的同一样本有相似的输出。这里“变换”包括高斯噪声、随机旋转、颜色的改变等等。Consistency learning主要有三类做法：mean teacher，CPC，PseudoSeg。\n",
    "\n",
    "PseudoSeg是google发表在ICLR 2021的工作。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fcdc3af705b14d3994c6105985cd6923c0814bc7eb4649fc90f56cf57725ff9d)\n",
    "\n",
    "\n",
    "对输入的图像X做两次不同的数据增强，一种“弱增强”（random crop/resize/flip），一种“强增强”(color jittering)。他们将两个增强后图像输入同一个网络f(θ)，得到两个不同的输出。因为“弱增强”下训练更加稳定，他们用“弱增强”后的图像作为target。\n",
    "\n",
    "## 2.通过了解半监督分割的工作进展，形成Self-training和Consistency learning结合的思路：训练采用Self-training方法，伪标签的处理采用Consistency learning方法，多次迭代训练，推理时多尺度和翻转增强，最后融合多次最好的结果。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、工作步骤\n",
    "\n",
    "1.采用Paddleseg作为平台，略作一些修改，适用于数据集训练。\n",
    "\n",
    "（1）PaddleSeg/paddleseg/datasets/dataset.py\n",
    "\n",
    "             ####标签处理\n",
    "             \n",
    "            label = np.asarray(Image.open(label_path).convert('L'))\n",
    "            \n",
    "            \n",
    "            if max(np.unique(label))>1:\n",
    "            \n",
    "                label = label/255.\n",
    "                \n",
    "            label = label.astype(\"int64\")\n",
    "            \n",
    "            label = label[np.newaxis, :, :]\n",
    "            \n",
    " （2）PaddleSeg/paddleseg/core/predict.py\n",
    " \n",
    "            #保存单通道label图像\n",
    "            \n",
    "            results_saved_dir = os.path.join(save_dir, 'results')\n",
    "            \n",
    "            results_image_path = os.path.join(results_saved_dir, im_file.rsplit(\".\")[0] + \".jpg\")\n",
    "            \n",
    "            mkdir(results_image_path)\n",
    "            \n",
    "            pred = pred.astype(\"float32\")*255\n",
    "            \n",
    "            pred = pred.astype(\"uint8\")\n",
    "            \n",
    "            cv2.imwrite(results_image_path, pred)\n",
    "            \n",
    "            #######\n",
    " \n",
    "（2）模型选用在FCN基础上修改的Fcn2，增加了OCRHead，并对两个分割头的结果进行早期平均融合。文件为PaddleSeg/paddleseg/models/fcn2.py\n",
    "\n",
    "     def __init__(.....\n",
    "        self.head = FCNHead(\n",
    "            num_classes,\n",
    "            backbone_indices,\n",
    "            backbone_channels,\n",
    "            channels,\n",
    "            bias=bias)\n",
    "\n",
    "        self.Ohead = OCRHead(\n",
    "            num_classes=num_classes,\n",
    "            in_channels=backbone_channels)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        avg_list = []\n",
    "        feat_list = self.backbone(x)\n",
    "        logit_list = self.head(feat_list)\n",
    "        logit_list1 = self.Ohead(feat_list)\n",
    "        avg_logit=(logit_list[0]+logit_list1[0])/2\n",
    "        avg_list.append(avg_logit)\n",
    "        #avg_list.append(logit_list1[1])\n",
    "        return [\n",
    "            F.interpolate(\n",
    "                logit,\n",
    "                paddle.shape(x)[2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=self.align_corners) for logit in avg_list\n",
    "        ]\n",
    "\n",
    "\n",
    "（3）初次训练采用有监督的数据集进行训练，利用初次训练的模型为测试集生成伪标签，将伪标签加入训练集，进行迭代训练。\n",
    "\n",
    "fcn2.yml为有监督的数据集训练配置文件， Backbone为加了SE的HRNet_W48，训练一次，学习率为0.01，次数为20000，数据增强是垂直和水平翻转。\n",
    "\n",
    "fcn2_pl.yml为有伪标签的数据集训练配置文件，模型与有监督训练一致，预训练模型采用有监督训练的最好模型，一般迭代训练三次，次数为40000，学习率每次为前一次的一半左右，分别0.01,0.005,0.003，数据增强是垂直和水平翻转,融合多次推理结果，形成新的伪标签。\n",
    "\n",
    "\n",
    "\n",
    "## **注：以下过程，保留了有监督训练过程。半监督训练过程，需要手工取消注释。**\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 六、数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\r\n",
    "sys.path.append(\"/home/aistudio/PaddleSeg\")\r\n",
    "import paddleseg\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from tqdm import tqdm\r\n",
    "import random\r\n",
    "#设置随机数种子\r\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#写数据文件\r\n",
    "def write_txt(file_name, imgs_path, labels_path=None, mode='train', val_pro=0.2):\r\n",
    "    assert mode==\"train\" or mode==\"test\", \"ERROR:mode must be train or test.\"\r\n",
    "    if mode!=\"test\":\r\n",
    "        train_path = []\r\n",
    "        for idx, f_path in enumerate(imgs_path):\r\n",
    "            for i_path in sorted(os.listdir(f_path)):\r\n",
    "                path1 = os.path.join(f_path, i_path) \r\n",
    "                path2 = os.path.join(labels_path[idx], i_path)\r\n",
    "                train_path.append((path1, path2, str(idx)))\r\n",
    "        \r\n",
    "        if val_pro>=0 and val_pro<=1:\r\n",
    "            #打乱数据\r\n",
    "            random.shuffle(train_path)\r\n",
    "            val_len = int(len(train_path)*val_pro)\r\n",
    "            val_path = train_path[:val_len]\r\n",
    "            train_path = train_path[val_len:]\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")\r\n",
    "            with open(file_name[1], 'w') as f:\r\n",
    "                for path in val_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")  \r\n",
    "            return len(train_path), val_len\r\n",
    "        else:\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\") \r\n",
    "            return len(train_path), 0\r\n",
    "    else:\r\n",
    "        with open(file_name, 'w') as f:\r\n",
    "            for path in imgs_path:\r\n",
    "                img_path = os.path.join(test_path, path)\r\n",
    "                f.write(img_path+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6.1生成有监督训练集\n",
    "第一次训练时，生成有监督训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成不含伪标注训练集\r\n",
    "def create_txt(data_root, train_imgs_dir=None, train_labels_dir=None, test_dir=None, val_pro=0.2):\r\n",
    "    if train_imgs_dir is not None:\r\n",
    "        if os.path.exists(\"train.txt\"):\r\n",
    "            os.remove(\"train.txt\")\r\n",
    "        if os.path.exists(\"val.txt\"):\r\n",
    "            os.remove(\"val.txt\")\r\n",
    "        train_imgs_dir = os.path.join(data_root, train_imgs_dir)\r\n",
    "        train_labels_dir = os.path.join(data_root, train_labels_dir)\r\n",
    "        file_names = os.listdir(train_imgs_dir)\r\n",
    "        file_names = sorted(file_names)\r\n",
    "        train_imgs_path, train_labels_path =[], []\r\n",
    "        for na in file_names:\r\n",
    "            train_imgs_path.append(os.path.join(train_imgs_dir, na))\r\n",
    "            train_labels_path.append(os.path.join(train_labels_dir, na))\r\n",
    "        train_len, val_len = write_txt([\"train.txt\", \"val.txt\"], train_imgs_path, train_labels_path, mode='train', val_pro=val_pro)\r\n",
    "        \r\n",
    "        print(\"训练数据整理完毕！训练集长度：{}，验证集长度：{}， 类别数：{}\".format(train_len, val_len, len(file_names)))\r\n",
    "\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"test.txt\"):\r\n",
    "            os.remove(\"test.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成不含伪标注的训练文件\r\n",
    "data_root = \"data\"\r\n",
    "train_imgs_dir = \"train_image\"\r\n",
    "train_labels_dir = \"train_50k_mask\"\r\n",
    "test_dir = \"test_image\"\r\n",
    "create_txt(data_root, train_imgs_dir, train_labels_dir, test_dir, val_pro=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6.2 生成半监督数据集\n",
    "迭代训练时，根据前次最好的模型生成伪标注，形成半监督训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#利用上次训练模型，生成伪标注，加入数据集\r\n",
    "'''\r\n",
    "!mkdir data/train_image/pl\r\n",
    "!mkdir data/train_50k_mask/pl\r\n",
    "!cp data/val_image/* data/train_image/pl/\r\n",
    "!cp data/test_image/* data/train_image/pl/\r\n",
    "!cp work/vote728/* data/train_50k_mask/pl\r\n",
    "!cp work/output_fcn2_pl_msf_4k_0.76667_0805/result_1/results/* data/train_50k_mask/pl\r\n",
    "!rename 's/\\.JPEG/\\.jpg/' data/train_image/pl/*.JPEG\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成伪标注训练集\r\n",
    "'''\r\n",
    "def create_pl_txt(data_root, train_imgs_dir=None, train_labels_dir=None, test_dir=None, val_pro=0.2):\r\n",
    "    if train_imgs_dir is not None:\r\n",
    "        if os.path.exists(\"train_pl.txt\"):\r\n",
    "            os.remove(\"train_pl.txt\")\r\n",
    "        if os.path.exists(\"val_pl.txt\"):\r\n",
    "            os.remove(\"val_pl.txt\")\r\n",
    "        train_imgs_dir = os.path.join(data_root, train_imgs_dir)\r\n",
    "        train_labels_dir = os.path.join(data_root, train_labels_dir)\r\n",
    "        file_names = os.listdir(train_imgs_dir)\r\n",
    "        file_names = sorted(file_names)\r\n",
    "        train_imgs_path, train_labels_path =[], []\r\n",
    "        for na in file_names:\r\n",
    "            train_imgs_path.append(os.path.join(train_imgs_dir, na))\r\n",
    "            train_labels_path.append(os.path.join(train_labels_dir, na))\r\n",
    "        train_len, val_len = write_txt([\"train_pl.txt\", \"val_pl.txt\"], train_imgs_path, train_labels_path, mode='train', val_pro=val_pro)\r\n",
    "        \r\n",
    "        print(\"训练数据整理完毕！训练集长度：{}，验证集长度：{}， 类别数：{}\".format(train_len, val_len, len(file_names)))\r\n",
    "\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"test_pl.txt\"):\r\n",
    "            os.remove(\"test_pl.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test_pl.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "data_root = \"data\"\r\n",
    "train_imgs_dir = \"train_image\"\r\n",
    "train_labels_dir = \"train_50k_mask\"\r\n",
    "test_dir = \"test_image\"\r\n",
    "create_pl_txt(data_root, train_imgs_dir, train_labels_dir, test_dir, val_pro=0.2)\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 七、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#有监督训练\r\n",
    "!python PaddleSeg/train.py --config fcn2.yml --do_eval --use_vdl --save_dir /home/aistudio/model_fcn2 --save_interval 10000 #--resume_model model_fcn3_pl/iter_60000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#半监督训练，迭代三次，采用含有伪标注的数据集，需要手工修改为预训练模型为上次训练好的模型，学习率0.01，0.005，0.003，训练40000次\r\n",
    "#!python PaddleSeg/train.py --config fcn2_pl.yml --do_eval --use_vdl --save_dir /home/aistudio/model_fcn2_pl --save_interval 10000 #--resume_model model_fcn3_pl/iter_60000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 八、推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#有监督：用不含伪标注的训练模模型推理，推理加翻转和多尺度0.8,1,1.2融合\r\n",
    "#!python PaddleSeg/predict.py --config fcn2.yml --model_path model_fcn2/best_model/model.pdparams --image_path data/test_image --save_dir output/result_1 --flip_horizontal --flip_vertical --aug_pred --scales 0.8 1 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#半监督：用含伪标注训练的模模型推理，推理加翻转和多尺度0.8,1,1.2融合\r\n",
    "!python PaddleSeg/predict.py --config fcn2_pl.yml --model_path work/model_fcn2_pl_0805/best_model/model.pdparamss --image_path data/test_image --save_dir output/result_1 --flip_horizontal --flip_vertical --aug_pred --scales 0.8 1 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 九、提交\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "\n",
      "zip error: Interrupted (aborting)\n",
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "#单模型结果提交\r\n",
    "%cd output/result_1/results\r\n",
    "!zip -r -oq /home/aistudio/predb.zip ./\r\n",
    "%cd /home/aistudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#多阶段模型结果融合\r\n",
    "#!python work/vote.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%cd work/vote0805/\r\n",
    "#!zip -r -oq /home/aistudio/work/vote0805.zip ./\r\n",
    "#%cd /home/aistudio/work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "   此次参赛，主要是为了学习和研究半监督学习方向的最新工作进展，读了一些论文，并在比赛中进行实验，收获良多。\n",
    "   \n",
    "   半监督学习采用多种方法相结合，形成端到端的方法，是最有前景的研究和应用方向。\n",
    "   \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
